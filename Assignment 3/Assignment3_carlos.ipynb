{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non linear programing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate random data, at least m=1000 observations, from a predefined linear regression model with at least n=100 variables. Assume that the regression coefficients ùú∑=(ùõΩ1,‚Ä¶,ùõΩùëñ,‚Ä¶,ùõΩùëõ) are integers where: ‚àí5‚â§ùõΩùëñ‚â§5 ‚àÄùëñ. Assume also normal residuals (ùëí~ùëÅ(0,ùúé))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "m = 1000 ;\n",
    "n = 100;\n",
    "sigma = 10; # Only a first value\n",
    "\n",
    "X0 = np.ones([m,1])\n",
    "#np.random.seed(0)\n",
    "X1 = np.random.uniform(0,10, ([m,n]))\n",
    "X = np.concatenate([X0,X1],axis = 1)\n",
    "np.savetxt(\"VariableX.txt\",X)\n",
    "error = np.random.normal (0,sigma,(m,1))\n",
    "beta = np.random.randint(-5, 5, size= ([n+1,1]))\n",
    "Y = np.dot(X,beta)+error\n",
    "np.savetxt(\"VariableY.txt\",Y)\n",
    "#print(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Estimate the value of the regression coefficients by using the analytical solution for the least squares estimation problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-12.80148123]\n",
      " [  2.02315799]\n",
      " [ -2.83327817]\n",
      " [  1.10931473]\n",
      " [ -4.00819808]\n",
      " [  3.21362022]\n",
      " [ -2.80823993]\n",
      " [ -3.15944649]\n",
      " [ -1.82769344]\n",
      " [ -0.03478562]\n",
      " [  3.07342417]\n",
      " [  2.10272571]\n",
      " [  3.21230504]\n",
      " [ -0.98493778]\n",
      " [ -2.92192449]\n",
      " [  4.00635617]\n",
      " [ -4.14285432]\n",
      " [ -1.70654683]\n",
      " [  3.96672877]\n",
      " [  4.06179884]\n",
      " [ -3.94814221]\n",
      " [  3.98089193]\n",
      " [  1.0521138 ]\n",
      " [  0.1321263 ]\n",
      " [ -1.0493243 ]\n",
      " [  2.09933889]\n",
      " [  0.79615279]\n",
      " [  1.89999252]\n",
      " [ -1.90755422]\n",
      " [ -4.24067259]\n",
      " [  3.88943055]\n",
      " [ -3.0990061 ]\n",
      " [ -4.14332935]\n",
      " [ -3.00697585]\n",
      " [  2.95442801]\n",
      " [ -3.05961079]\n",
      " [  0.86957953]\n",
      " [  0.95713132]\n",
      " [ -4.03168188]\n",
      " [ -3.84221915]\n",
      " [ -2.04394447]\n",
      " [  0.04496062]\n",
      " [  0.12712519]\n",
      " [  2.04347987]\n",
      " [ -4.00887338]\n",
      " [ -2.01530972]\n",
      " [ -4.98352612]\n",
      " [  1.06935986]\n",
      " [ -1.97742574]\n",
      " [  3.95021791]\n",
      " [ -3.92781882]\n",
      " [  3.91865661]\n",
      " [ -3.10784065]\n",
      " [  1.02420172]\n",
      " [  2.11132248]\n",
      " [  2.04151894]\n",
      " [ -4.82423611]\n",
      " [  4.07516065]\n",
      " [ -3.97528029]\n",
      " [ -2.99810971]\n",
      " [ -2.13874614]\n",
      " [  2.2176153 ]\n",
      " [ -0.02800426]\n",
      " [ -0.94524787]\n",
      " [  4.01645442]\n",
      " [ -0.86632704]\n",
      " [ -0.02989609]\n",
      " [ -0.92099833]\n",
      " [  0.99296   ]\n",
      " [  3.95158801]\n",
      " [  0.20476381]\n",
      " [ -0.14456871]\n",
      " [ -4.0581105 ]\n",
      " [  1.99853113]\n",
      " [  0.91213212]\n",
      " [  0.94121568]\n",
      " [ -2.88712079]\n",
      " [  0.83036847]\n",
      " [ -2.00695228]\n",
      " [ -4.90572314]\n",
      " [  0.09827711]\n",
      " [ -2.20030649]\n",
      " [ -0.05329113]\n",
      " [ -3.13435415]\n",
      " [ -4.96530751]\n",
      " [ -5.01477747]\n",
      " [ -2.90895637]\n",
      " [ -4.12808116]\n",
      " [  1.0699397 ]\n",
      " [ -3.92297972]\n",
      " [ -5.11708124]\n",
      " [ -0.84387479]\n",
      " [ -0.78684143]\n",
      " [  2.14441244]\n",
      " [ -3.99651843]\n",
      " [ -0.78656387]\n",
      " [ -3.91058085]\n",
      " [  0.93690182]\n",
      " [  3.86801893]\n",
      " [ -2.97066688]\n",
      " [ -2.04489054]]\n"
     ]
    }
   ],
   "source": [
    "beta_ls = np.dot(np.dot(np.linalg.inv(np.dot(np.transpose(X),X)),np.transpose(X)),Y)\n",
    "print(beta_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Let ùú∑ÃÇ=(ùõΩÃÇ1,‚Ä¶,ùõΩÃÇùëñ,‚Ä¶,ùõΩÃÇùëõ) be the coefficient' estimations obtained in a) and ùú∑=(ùõΩ1,‚Ä¶,ùõΩùëñ,‚Ä¶,ùõΩùëõ) be their real value used to generate the data. We can define a measure ùúÜ of the estimation error as:\n",
    "\n",
    "ùúÜ=$\\frac{‚Äñùú∑‚àíùú∑ÃÇ‚Äñ}{‚Äñùú∑‚Äñ}√ó100$\n",
    "\n",
    "Analyze how the estimation error (ùúÜ) varies with ùúé (standard deviation assumed for the residuals). Make use of a graph to illustrate this relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#DECLARE LIST THAT WILL LAMBDA VALUES\n",
    "EstimError= [];\n",
    "\n",
    "#DEFINE RANGE FOR SIGMA\n",
    "sigma_values = np.arange(0.5,10000, 20) #from 0.5 to 30 in steps of 0.25\n",
    "\n",
    "for sigma in sigma_values:\n",
    "    Aux_error = np.random.normal (0,sigma,(m,1)) #generate error with normal distribution\n",
    "    Y_aux = np.dot(X,beta)+Aux_error                 #generate new prediction\n",
    "    beta_ls_aux = np.dot(np.dot(np.linalg.inv(np.dot(np.transpose(X),X)),\n",
    "                            np.transpose(X)),Y_aux) #Estimate Betas using LSE\n",
    "    #Use 2-norm to estimate the error\n",
    "    EstimError.append(np.linalg.norm(np.matrix(beta)-beta_ls_aux,2)/np.linalg.norm(beta,2)*100) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x10e18f750>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAFkCAYAAAAt0UHnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHhFi/WnaXtDyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d371c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.scatter(sigma_values,EstimError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Estimate the value of the regression coefficients (least squares) by using the tool minimize from the python package Scipy.optimize. Try at least three available solvers and compare their performance (iterations, function, gradient and hessian evaluations as well as total computational time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SLSQP Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "import time\n",
    "\n",
    "# Defining the function to minimize\n",
    "def squares(beta,X, Y):\n",
    "    return sum((Y[i]-np.dot(beta,X[i,].T))**2 for i in range(0,m)) \n",
    "\n",
    "#Create bounds (-5,5)\n",
    "bnds = []\n",
    "for i in range(0,n+1):\n",
    "    bnds.append((-5,5))\n",
    "    \n",
    "#Initial State of the Betas\n",
    "beta0 = np.zeros(n+1) #Initial state \n",
    "\n",
    "#************** SLSQP SOLVER **********************************\n",
    "start = time.time()\n",
    "beta_SLSQP = minimize(squares,\n",
    "                  beta0,\n",
    "                  args=(X, Y),\n",
    "                  method='SLSQP',\n",
    "                  bounds=bnds,\n",
    "                  options={'disp': False,'ftol': 1e-15})\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution time of SLSQP is: 1.4216\n",
      "Number of iterations: 5\n",
      "Number of evaluations of Obj. Function: 103\n",
      "Final value of Obj. Function: [  1.24581386e+08]\n",
      "Number of evaluations of Gradient: 1\n",
      "Hessian not used\n",
      "error = 100.0000\n"
     ]
    }
   ],
   "source": [
    "#Print Results\n",
    "print '\\nExecution time of SLSQP is: {0:.4f}'.format(end - start)\n",
    "print 'Number of iterations: {0}'.format(beta_SLSQP.nit)\n",
    "print 'Number of evaluations of Obj. Function: {0}'.format(beta_SLSQP.nfev)\n",
    "print 'Final value of Obj. Function: {0!s}'.format(beta_SLSQP.fun)\n",
    "if 'njev' in beta_SLSQP.keys():\n",
    "    print 'Number of evaluations of Gradient: {0}'.format(beta_SLSQP.njev)\n",
    "else:\n",
    "    print 'Gradient not used' \n",
    "\n",
    "if 'nhev' in beta_SLSQP.keys():\n",
    "    print 'Number of evaluations of Hessian: {0}'.format(beta_SLSQP.nhev)\n",
    "else:\n",
    "    print 'Hessian not used' \n",
    "print 'error = {0:.4f}'.format(np.linalg.norm(np.matrix(beta)-np.transpose(np.matrix(beta_SLSQP.x)),2)/np.linalg.norm(beta,2)*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L-BFGS-B Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d02acfab7563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                   \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L-BFGS-B'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                   \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbnds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                   options={'disp': False,'ftol': 1e-15})\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Emilie/anaconda/lib/python2.7/site-packages/scipy/optimize/_minimize.pyc\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 450\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    451\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m/Users/Emilie/anaconda/lib/python2.7/site-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Emilie/anaconda/lib/python2.7/site-packages/scipy/optimize/lbfgsb.pyc\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Emilie/anaconda/lib/python2.7/site-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[0;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mei\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m         \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m         \u001b[0mei\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Emilie/anaconda/lib/python2.7/site-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-92d50165426d>\u001b[0m in \u001b[0;36msquares\u001b[0;34m(beta, X, Y)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Defining the function to minimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msquares\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#Create bounds (-5,5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-92d50165426d>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((i,))\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Defining the function to minimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msquares\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#Create bounds (-5,5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#************** L-BFGS-B SOLVER **********************************\n",
    "start = time.time()\n",
    "beta_LBFGSB = minimize(squares,\n",
    "                  beta0,\n",
    "                  args=(X, Y),\n",
    "                  method='L-BFGS-B',\n",
    "                  bounds=bnds,\n",
    "                  options={'disp': False,'ftol': 1e-15})\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution time of L-BFGS-B is: -51.1648\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'beta_LBFGSB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-034532f4b118>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Print Results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'\\nExecution time of L-BFGS-B is: {0:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Number of iterations: {0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_LBFGSB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Number of evaluations of Obj. Function: {0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_LBFGSB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Final value of Obj. Function: {0!s}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_LBFGSB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'beta_LBFGSB' is not defined"
     ]
    }
   ],
   "source": [
    "#Print Results\n",
    "print '\\nExecution time of L-BFGS-B is: {0:.4f}'.format(end - start)\n",
    "print 'Number of iterations: {0}'.format(beta_LBFGSB.nit)\n",
    "print 'Number of evaluations of Obj. Function: {0}'.format(beta_LBFGSB.nfev)\n",
    "print 'Final value of Obj. Function: {0!s}'.format(beta_LBFGSB.fun)\n",
    "if 'njev' in beta_LBFGSB.keys():\n",
    "    print 'Number of evaluations of Gradient: {0}'.format(beta_LBFGSB.njev)\n",
    "else:\n",
    "    print 'Gradient not used' \n",
    "\n",
    "if 'nhev' in beta_LBFGSB.keys():\n",
    "    print 'Number of evaluations of Hessian: {0}'.format(beta_LBFGSB.nhev)\n",
    "else:\n",
    "    print 'Hessian not used'  \n",
    "print 'error = {0:.4f}'.format(np.linalg.norm(np.matrix(beta)-np.transpose(np.matrix(beta_LBFGSB.x)),2)/np.linalg.norm(beta,2)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TNC Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#************** TNC SOLVER **********************************\n",
    "start = time.time()\n",
    "beta_TNC = minimize(squares,\n",
    "                  beta0,\n",
    "                  args=(X, Y),\n",
    "                  method='TNC',\n",
    "                  bounds=bnds,\n",
    "                  options={'disp': False,'ftol': 1e-15})\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution time of L-BFGS-B is: 315.4010\n",
      "Number of iterations: 101\n",
      "Number of evaluations of Obj. Function: 1010\n",
      "Final value of Obj. Function: [ 248210.01265036]\n",
      "Gradient not used\n",
      "Hessian not used\n",
      "error = 22.9045\n"
     ]
    }
   ],
   "source": [
    "#Print Results\n",
    "print '\\nExecution time of L-BFGS-B is: {0:.4f}'.format(end - start)\n",
    "print 'Number of iterations: {0}'.format(beta_TNC.nit)\n",
    "print 'Number of evaluations of Obj. Function: {0}'.format(beta_TNC.nfev)\n",
    "print 'Final value of Obj. Function: {0!s}'.format(beta_TNC.fun)\n",
    "if 'njev' in beta_TNC.keys():\n",
    "    print 'Number of evaluations of Gradient: {0}'.format(beta_TNC.njev)\n",
    "else:\n",
    "    print 'Gradient not used' \n",
    "\n",
    "if 'nhev' in beta_TNC.keys():\n",
    "    print 'Number of evaluations of Hessian: {0}'.format(beta_TNC.nhev)\n",
    "else:\n",
    "    print 'Hessian not used'  \n",
    "print 'error = {0:.4f}'.format(np.linalg.norm(np.matrix(beta)-np.transpose(np.matrix(beta_TNC.x)),2)/np.linalg.norm(beta,2)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Considering again the least squares estimation problem, estimate the value of the regression coefficients\n",
    "by implementing the:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\rightarrow$ Definition objective function, gradient and Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#definitinition of OF\n",
    "def least_sq_reg(beta_ls, X, Y):\n",
    "    beta_ls=np.matrix(beta_ls)\n",
    "    z=Y-X*np.transpose(beta_ls)\n",
    "    return np.transpose(z)*z\n",
    "\n",
    "#definition of Gradient\n",
    "def least_sq_reg_der(beta_ls,X,Y):\n",
    "    beta_ls=np.matrix(beta_ls)\n",
    "    pp=-2*np.transpose(Y-X*np.transpose(beta_ls))*X\n",
    "    aa= np.squeeze(np.asarray(pp))\n",
    "    return aa\n",
    "\n",
    "#definition of hessian\n",
    "def least_sq_reg_hess(beta_ls,X,Y):\n",
    "    ss=2*np.dot(np.transpose(X),X)\n",
    "    return ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(a,b)=X.shape\n",
    "beta_lsg=np.zeros(b) #initial value for beta\n",
    "n_iter=100000 #maximim nunber iteration\n",
    "OF_iter=np.zeros(n_iter)\n",
    "tol_iter=np.zeros(n_iter)\n",
    "alpha_iter=np.zeros(n_iter)\n",
    "i=0;\n",
    "tol=1000;\n",
    "epsilon=1e-3;\n",
    "\n",
    "time_start = time.clock()\n",
    "while (i <= n_iter-2) and (tol>epsilon):\n",
    "    i=i+1\n",
    "    grad = least_sq_reg_der(beta_lsg,X,Y)\n",
    "    ddirect = - grad\n",
    "    ###################################\n",
    "    #      Armijo Rule-----Choose an appropiate alpha\n",
    "    sigma = 0.1\n",
    "    beta_half = 0.5\n",
    "    alpha = 1\n",
    "    while (least_sq_reg(beta_lsg + alpha*ddirect , X, Y)> least_sq_reg(beta_lsg, X, Y) + alpha*sigma*np.dot(grad,ddirect)):\n",
    "        alpha = alpha*beta_half\n",
    "    ###################################\n",
    "    beta_lsg = beta_lsg + alpha*ddirect\n",
    "    OF_iter[i] = least_sq_reg(beta_lsg, X, Y)\n",
    "    tol = np.linalg.norm(grad,ord=2)\n",
    "    tol_iter[i] = tol\n",
    "    alpha_iter[i] = alpha\n",
    "time_elapsed = (time.clock() - time_start)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution time of Gradient Method is: 180.9180\n",
      "Number of iterations: 99999\n",
      "Number of evaluations of Obj. Function: 99999\n",
      "Final value of Obj. Function: 85442.060907\n",
      "Number of evaluations of Gradient: 99999\n",
      "Hessian not used\n",
      "error = 15.0492\n"
     ]
    }
   ],
   "source": [
    "#Print Results\n",
    "print '\\nExecution time of Gradient Method is: {0:.4f}'.format(time_elapsed)\n",
    "print 'Number of iterations: {0}'.format(i)\n",
    "print 'Number of evaluations of Obj. Function: {0}'.format(i)\n",
    "print 'Final value of Obj. Function: {0:4f}'.format(OF_iter[i])\n",
    "print 'Number of evaluations of Gradient: {0}'.format(i)\n",
    "print 'Hessian not used'\n",
    "print 'error = {0:.4f}'.format(np.linalg.norm(np.matrix(beta)-np.transpose(np.matrix(beta_lsg)),2)/np.linalg.norm(beta,2)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Newton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(a,b)=X.shape\n",
    "beta_newton=np.zeros(b) #initial value for beta\n",
    "n_iter=100000 #maximim nunber iteration\n",
    "OF_iter=np.zeros(n_iter)\n",
    "tol_iter=np.zeros(n_iter)\n",
    "alpha_iter=np.zeros(n_iter)\n",
    "alpha_iter=np.zeros(n_iter)\n",
    "i=0;\n",
    "tol=1000;\n",
    "epsilon=1e-8;\n",
    "\n",
    "time_start = time.clock()\n",
    "while (i <= n_iter-2) and (tol>epsilon):\n",
    "    i=i+1\n",
    "    grad = least_sq_reg_der(beta_newton,X,Y)\n",
    "    hess = least_sq_reg_hess(beta_newton,X,Y)\n",
    "    ddirect = - np.dot(np.linalg.inv(hess),grad)\n",
    "    ###################################\n",
    "    #      Armijo Rule-----Choose an appropiate alpha\n",
    "    sigma = 0.1\n",
    "    beta_half = 0.5\n",
    "    alpha = 1\n",
    "    while (least_sq_reg(beta_newton + alpha*ddirect , X, Y)> least_sq_reg(beta_newton, X, Y) + alpha*sigma*np.dot(grad,ddirect)):\n",
    "        alpha = alpha*beta_half\n",
    "    ###################################\n",
    "    beta_newton = beta_newton + alpha*ddirect\n",
    "    OF_iter[i] = least_sq_reg(beta_newton, X, Y)\n",
    "    tol = np.linalg.norm(grad,ord=2)\n",
    "    tol_iter[i] = tol\n",
    "    alpha_iter[i] = alpha\n",
    "time_elapsed = (time.clock() - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution time of Newton Method is: 0.0032\n",
      "Number of iterations: 3\n",
      "Number of evaluations of Obj. Function: 3\n",
      "Final value of Obj. Function: 85441.836378\n",
      "Number of evaluations of Gradient: 3\n",
      "Number of evaluations of Hessian: 3\n",
      "error = 15.9964\n"
     ]
    }
   ],
   "source": [
    "#Print Results\n",
    "print '\\nExecution time of Newton Method is: {0:.4f}'.format(time_elapsed)\n",
    "print 'Number of iterations: {0}'.format(i)\n",
    "print 'Number of evaluations of Obj. Function: {0}'.format(i)\n",
    "print 'Final value of Obj. Function: {0:4f}'.format(OF_iter[i])\n",
    "print 'Number of evaluations of Gradient: {0}'.format(i)\n",
    "print 'Number of evaluations of Hessian: {0}'.format(i)\n",
    "print 'error = {0:.4f}'.format(np.linalg.norm(np.matrix(beta)-np.transpose(np.matrix(beta_newton)),2)/np.linalg.norm(beta,2)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quasi-Newton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(a,b)=X.shape\n",
    "beta_quasi=np.zeros(b) #initial value for beta\n",
    "n_iter=100000 #maximim nunber iteration\n",
    "OF_iter=np.zeros(n_iter)\n",
    "tol_iter=np.zeros(n_iter)\n",
    "alpha_iter=np.zeros(n_iter)\n",
    "alpha_iter=np.zeros(n_iter)\n",
    "i=0;\n",
    "tol=1000;\n",
    "epsilon=1e-8;\n",
    "\n",
    "time_start = time.clock()\n",
    "while (i <= n_iter-2) and (tol>epsilon):\n",
    "    i=i+1\n",
    "    grad = least_sq_reg_der(beta_quasi,X,Y)\n",
    "    if (i==1):\n",
    "        grad = least_sq_reg_der(beta_quasi,X,Y)\n",
    "        B = least_sq_reg_hess(beta_quasi,X,Y)\n",
    "    else:\n",
    "        grad_before = grad\n",
    "        grad = least_sq_reg_der(beta_quasi,X,Y)\n",
    "        y = grad - grad_before\n",
    "        s = beta_quasi - beta_quasi_before\n",
    "        B_before = B\n",
    "        B = B_before + np.dot(y-np.dot(B,s),np.transpose(y-np.dot(B,s)))/(np.dot(np.transpose(y-np.dot(B,s)),s))\n",
    "    ddirect = - np.dot(np.linalg.inv(B),grad)\n",
    "    ###################################\n",
    "    #      Armijo Rule-----Choose an appropiate alpha\n",
    "    sigma = 0.1\n",
    "    beta_half = 0.5\n",
    "    alpha = 1\n",
    "    while (least_sq_reg(beta_quasi + alpha*ddirect , X, Y)> least_sq_reg(beta_quasi, X, Y) + alpha*sigma*np.dot(grad,ddirect)):\n",
    "        alpha = alpha*beta_half\n",
    "    ###################################\n",
    "    beta_quasi_before = beta_quasi\n",
    "    beta_quasi = beta_quasi_before + alpha*ddirect\n",
    "    OF_iter[i] = least_sq_reg(beta_quasi, X, Y)\n",
    "    tol = np.linalg.norm(grad,ord=2)\n",
    "    tol_iter[i] = tol\n",
    "    alpha_iter[i] = alpha   \n",
    "time_elapsed = (time.clock() - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution time of Quasi-Newton Method is: 0.0032\n",
      "Number of iterations: 3\n",
      "Number of evaluations of Obj. Function: 3\n",
      "Final value of Obj. Function: 85441.836378\n",
      "Number of evaluations of Gradient: 3\n",
      "Number of evaluations of Hessian: 1\n",
      "error = 15.9964\n"
     ]
    }
   ],
   "source": [
    "#Print Results\n",
    "print '\\nExecution time of Quasi-Newton Method is: {0:.4f}'.format(time_elapsed)\n",
    "print 'Number of iterations: {0}'.format(i)\n",
    "print 'Number of evaluations of Obj. Function: {0}'.format(i)\n",
    "print 'Final value of Obj. Function: {0:4f}'.format(OF_iter[i])\n",
    "print 'Number of evaluations of Gradient: {0}'.format(i)\n",
    "print 'Number of evaluations of Hessian: {0}'.format(1)\n",
    "print 'error = {0:.4f}'.format(np.linalg.norm(np.matrix(beta)-np.transpose(np.matrix(beta_quasi)),2)/np.linalg.norm(beta,2)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Estimate the value of the regression coefficients y implementing the coordinate gradient method and the stochastic gradient method. Compare their performance with the algorithms in c)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinate gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random \n",
    "(a,b)=X.shape\n",
    "#alpha = 0.00001\n",
    "beta_coor=np.zeros(b) #initial value for beta\n",
    "n_iter=100000 #maximim nunber iteration\n",
    "OF_iter=np.zeros(n_iter)\n",
    "tol_iter=np.zeros(n_iter)\n",
    "alpha_iter=np.zeros(n_iter)\n",
    "i=0;\n",
    "tol=1000;\n",
    "epsilon=1e-3;\n",
    "\n",
    "time_start = time.clock()\n",
    "while (i <= n_iter-2) and (tol>epsilon):\n",
    "    i=i+1\n",
    "    grad = least_sq_reg_der(beta_coor,X,Y)\n",
    "    ddirect =np.zeros(b)\n",
    "    j = random.randint(0, b-1)\n",
    "    ddirect[j] = - grad[j]\n",
    "    ###################################\n",
    "    #      Armijo Rule-----Choose an appropiate alpha\n",
    "    sigma = 0.1\n",
    "    beta_half = 0.5\n",
    "    alpha = 1\n",
    "    while (least_sq_reg(beta_coor + alpha*ddirect , X, Y)> least_sq_reg(beta_coor, X, Y) + alpha*sigma*np.dot(grad,ddirect)):\n",
    "          alpha = alpha*beta_half\n",
    "    ###################################\n",
    "    beta_coor = beta_coor + alpha*ddirect\n",
    "    OF_iter[i] = least_sq_reg(beta_coor, X, Y)\n",
    "    tol = np.linalg.norm(grad,ord=2)\n",
    "    tol_iter[i] = tol\n",
    "    alpha_iter[i] = alpha\n",
    "\n",
    "time_elapsed = (time.clock() - time_start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution time of Coordinate Gradient Method is: 130.7382\n",
      "Number of iterations: 99999\n",
      "Number of evaluations of Obj. Function: 99999\n",
      "Final value of Obj. Function: 85441.845101\n",
      "Number of evaluations of Gradient: 99999\n",
      "Hessian not used\n",
      "error = 15.8094\n"
     ]
    }
   ],
   "source": [
    "#Print Results\n",
    "print '\\nExecution time of Coordinate Gradient Method is: {0:.4f}'.format(time_elapsed)\n",
    "print 'Number of iterations: {0}'.format(i)\n",
    "print 'Number of evaluations of Obj. Function: {0}'.format(i)\n",
    "print 'Final value of Obj. Function: {0:4f}'.format(OF_iter[i])\n",
    "print 'Number of evaluations of Gradient: {0}'.format(i)\n",
    "print 'Hessian not used'\n",
    "print 'error = {0:.4f}'.format(np.linalg.norm(np.matrix(beta)-np.transpose(np.matrix(beta_coor)),2)/np.linalg.norm(beta,2)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#definition of partial gradient \n",
    "def least_sq_reg_der_par(beta_ls,X,Y,i):\n",
    "    beta_ls=np.matrix(beta_ls)\n",
    "    pp=-2*(Y[i]-X[i,]*np.transpose(beta_ls))*X[i,]\n",
    "    aa= np.squeeze(np.asarray(pp))\n",
    "    return aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "(a,b)=X.shape\n",
    "#alpha = 0.0001\n",
    "beta_sto=np.zeros(b) #initial value for beta\n",
    "n_iter=100000 #maximum nunber iteration\n",
    "OF_iter=np.zeros(n_iter)\n",
    "tol_iter=np.zeros(n_iter)\n",
    "alpha_iter=np.zeros(n_iter)\n",
    "i=0;\n",
    "tol=1000;\n",
    "epsilon=1e-3;\n",
    "\n",
    "time_start = time.clock()\n",
    "while (i <= n_iter-2) and (tol>epsilon):\n",
    "    i=i+1\n",
    "    j = random.randint(0, b-1)\n",
    "    grad_par = least_sq_reg_der_par(beta_sto,X,Y,j)\n",
    "    grad = least_sq_reg_der(beta_sto,X,Y)\n",
    "    ddirect = - grad_par\n",
    "    ###################################\n",
    "    #      Armijo Rule-----Choose an appropiate alpha\n",
    "    sigma = 0.1\n",
    "    beta_half = 0.5\n",
    "    alpha = 1\n",
    "    while (least_sq_reg(beta_sto + alpha*ddirect , X, Y)> least_sq_reg(beta_sto, X, Y) + alpha*sigma*np.dot(grad,ddirect)):\n",
    "           alpha = alpha*beta_half\n",
    "    ###################################\n",
    "    beta_sto = beta_sto + ddirect*alpha\n",
    "    OF_iter[i] = least_sq_reg(beta_sto, X, Y)\n",
    "    tol = np.linalg.norm(grad,ord=2)\n",
    "    tol_iter[i] = tol\n",
    "    alpha_iter[i] = alpha\n",
    "time_elapsed = (time.clock() - time_start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution time of Stochastic Gradient Method is: 257.0573\n",
      "Number of iterations: 99999\n",
      "Number of evaluations of Obj. Function: 99999\n",
      "Final value of Obj. Function: 1834117.258382\n",
      "Number of evaluations of Gradient: 99999\n",
      "Hessian not used\n",
      "error = 56.4157\n"
     ]
    }
   ],
   "source": [
    "#Print Results\n",
    "print '\\nExecution time of Stochastic Gradient Method is: {0:.4f}'.format(time_elapsed)\n",
    "print 'Number of iterations: {0}'.format(i)\n",
    "print 'Number of evaluations of Obj. Function: {0}'.format(i)\n",
    "print 'Final value of Obj. Function: {0:4f}'.format(OF_iter[i])\n",
    "print 'Number of evaluations of Gradient: {0}'.format(i)\n",
    "print 'Hessian not used'\n",
    "print 'error = {0:.4f}'.format(np.linalg.norm(np.matrix(beta)-np.transpose(np.matrix(beta_sto)),2)/np.linalg.norm(beta,2)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1834117.25838171]]\n"
     ]
    }
   ],
   "source": [
    "print(least_sq_reg(beta_sto, X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
