{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download csv data from:\n",
    "\n",
    "http://www.google.com/finance/historical?output=csv&q= [COMPANY KEY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from __future__ import division \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute the weekly returns for each stock value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04008257, -0.01304922, -0.01578643, -0.06508378,  0.00304169,\n",
       "       -0.01128628,  0.06203129, -0.02567846,  0.01782372, -0.01270239,\n",
       "        0.00382256,  0.00374231,  0.00937938, -0.00784212,  0.05518669,\n",
       "        0.02321779,  0.01830428, -0.06004384,  0.02220428,  0.00953507,\n",
       "        0.00070749,  0.00908237,  0.01719825,  0.01056176, -0.00207151,\n",
       "       -0.03695769,  0.00159236,  0.01880609, -0.05615053, -0.01405152,\n",
       "       -0.00779528, -0.00994986,  0.0254736 , -0.01707048,  0.02631579,\n",
       "        0.00883088,  0.02901354, -0.02261191, -0.06560339, -0.02382936,\n",
       "       -0.04577703, -0.04879786,  0.01718182,  0.01052824, -0.00248183,\n",
       "       -0.05731697,  0.07285889,  0.04029404,  0.04511013, -0.02447582])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "data_apple_open=np.array(pd.read_csv('aapl.csv',delimiter=',',usecols=['Open']))\n",
    "data_apple_close=np.array(pd.read_csv('aapl.csv',delimiter=',',usecols=['Close']))\n",
    "\n",
    "data_ebay_open=np.array(pd.read_csv('ebay.csv',delimiter=',',usecols=['Open']))\n",
    "data_ebay_close=np.array(pd.read_csv('ebay.csv',delimiter=',',usecols=['Close']))\n",
    "\n",
    "data_amazon_open=np.array(pd.read_csv('amzn.csv',delimiter=',',usecols=['Open']))\n",
    "data_amazon_close=np.array(pd.read_csv('amzn.csv',delimiter=',',usecols=['Close']))\n",
    "\n",
    "data_microsoft_open=np.array(pd.read_csv('msft.csv',delimiter=',',usecols=['Open']))\n",
    "data_microsoft_close=np.array(pd.read_csv('msft.csv',delimiter=',',usecols=['Close']))\n",
    "\n",
    "\n",
    "cont=-1;\n",
    "n=5;\n",
    "size=len(data_apple_open)\n",
    "data_apple=np.zeros(size//n)\n",
    "data_ebay=np.zeros(size//n)\n",
    "data_amazon=np.zeros(size//n)\n",
    "data_microsoft=np.zeros(size//n)\n",
    "for i in np.linspace(n+1,n*(size//n),size//n):\n",
    "    i=int(i)\n",
    "    if i >n:\n",
    "        cont=cont+1\n",
    "        data_apple[cont]=np.subtract(data_apple_close[i],data_apple_open[i-n])/data_apple_open[i-n]\n",
    "        data_ebay[cont]=(data_ebay_close[i]-data_ebay_open[i-n])/data_ebay_open[i-n]\n",
    "        data_amazon[cont]=(data_amazon_close[i]-data_amazon_open[i-n])/data_amazon_open[i-n]\n",
    "        data_microsoft[cont]=(data_microsoft_close[i]-data_microsoft_open[i-n])/data_microsoft_open[i-n]\n",
    "data_apple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean return vector $\\mu$ and the covariance matrix $\\Sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00088973  0.0242455  -0.0142025   0.00066933]\n",
      "[[  1.04152842e-03   9.44271695e-04   7.17481572e-04   5.15708614e-04]\n",
      " [  9.44271695e-04   3.59933459e-02  -6.58612794e-05   1.46089683e-03]\n",
      " [  7.17481572e-04  -6.58612794e-05   1.28670205e-03   4.33891329e-04]\n",
      " [  5.15708614e-04   1.46089683e-03   4.33891329e-04   1.48533899e-03]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#compute mean value vector\n",
    "mu=np.mean([data_apple,data_ebay,data_amazon,data_microsoft],axis=1)\n",
    "print(mu)\n",
    "#compute covarianze matrix\n",
    "covar=np.matrix(np.cov([data_apple,data_ebay,data_amazon,data_microsoft]))\n",
    "print(covar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We solve the portfolio optimization problem \n",
    "\n",
    "\\begin{align*}\n",
    "\\text{maximize}_x\\quad & \\mu^T x - \\frac{1}{2}\\ \\gamma\\ x^T \\Sigma x \\\\\n",
    "\\text{subject to}\\quad  & \\sum x_i = 1,\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: [[-0.03139668]]\n",
      "            Iterations: 15\n",
      "            Function evaluations: 90\n",
      "            Gradient evaluations: 15\n",
      "[ 4.38578348  0.10306454 -4.91170621  1.42285819]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def portfolio(x, mu, covar, gamma):\n",
    "    return -np.dot(x,mu)+0.5*gamma*np.dot(np.dot(x,covar),x)    \n",
    "\n",
    "cons = ({'type': 'eq','fun' : lambda x: sum(x)-1})\n",
    "bnds = ((0, 1), (0, 1), (0, 1), (0, 1))\n",
    "gamma=3\n",
    "x0 = np.array([0, 0, 0, 0])\n",
    "\n",
    "res = minimize(portfolio, x0, args=(mu, covar, gamma), method='SLSQP', constraints=cons, options={'disp': True,'ftol': 1e-10})\n",
    "#res = minimize(portfolio, x0, args=(mu, covar, gamma), method='SLSQP', constraints=cons, bounds=bnds, options={'disp': True,'ftol': 1e-10})\n",
    "print (res.x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From KKT conditions, the solution is:\n",
    "$$\n",
    "    x^* = \\frac{1}{\\gamma}\\Sigma^{-1}\\mu - \\frac{\\lambda_{\\gamma}}{\\gamma}\\Sigma^{-1} e,\n",
    "$$\n",
    "where $\\lambda_{\\gamma} = \\frac{\\mu^T \\Sigma^{-1} e - \\gamma}{e^T \\Sigma^{-1} e}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00651462]]\n",
      "[[ 4.38579003  0.10307012 -4.91172826  1.42286811]]\n"
     ]
    }
   ],
   "source": [
    "lambda_opt=(np.dot(np.dot(mu,np.linalg.inv(covar)),np.ones(mu.shape))-gamma)/np.dot(np.dot(np.ones(mu.shape),np.linalg.inv(covar)),np.ones(mu.shape))\n",
    "x_opt=(1/gamma)*np.dot(np.linalg.inv(covar),mu)-(1/gamma)*np.dot(lambda_opt,np.dot(np.linalg.inv(covar),np.ones(mu.shape)))\n",
    "print(lambda_opt)\n",
    "print(x_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We  can plot the efficient frontier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nmax=1000;\n",
    "expec_vector=np.zeros(nmax)\n",
    "risk_vector=np.zeros(nmax)\n",
    "cont=-1\n",
    "cons = ({'type': 'eq','fun' : lambda x: sum(x)-1})\n",
    "bnds = ((0, 1), (0, 1), (0, 1), (0, 1)) #incluyo reestricciones\n",
    "for gamma in np.linspace(1,100,nmax):\n",
    "    cont=cont+1\n",
    "    x0 = np.array([0, 0, 0, 0])\n",
    "    res = minimize(portfolio, x0, args=(mu, covar, gamma), method='SLSQP', constraints=cons,bounds=bnds, options={'disp': False,'ftol': 1e-15})  \n",
    "    x_opt=np.array(res.x)\n",
    "    mu=np.array(mu)\n",
    "    expec_vector[cont]=np.dot(mu,x_opt.T)\n",
    "    risk_vector[cont]=np.dot(np.dot(x_opt,covar),x_opt.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.collections.PathCollection at 0x17940e80>,\n",
       " <matplotlib.text.Text at 0x178c9eb8>,\n",
       " <matplotlib.text.Text at 0x26bd128>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAEPCAYAAADrvntcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x177d72e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.scatter(risk_vector,expec_vector),plt.ylabel('Expected value'),plt.xlabel('Risk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Lest solve it by applying a barrier method:\n",
    "$$\n",
    "\\min_x\\quad  -\\mu^T x + \\frac{1}{2}\\ \\gamma\\ x^T \\Sigma x  + \\frac{\\rho}{2}(x^Te - 1)^2\n",
    "$$\n",
    "\n",
    "$\\rightarrow$ Step 1: initial point $x^{(0)}$, penalization parameter $\\rho_1>0$ and $t=1$. Let $\\epsilon>0$ be the tolerance parameter and $\\eta >1$ a fixed parameter. \n",
    "\n",
    "$\\rightarrow$ Step 2: solve  $\\min_x\\quad  -\\mu^T x + \\frac{1}{2}\\ \\gamma\\ x^T \\Sigma x  + \\frac{\\rho_t}{2}(x^Te - 1)$, by a descent direction method (ex. gradient). Use $x^{(t-1)}$ as initial point. Solution$=x^{(t)}$. \n",
    "\n",
    "$\\rightarrow$ Step 3: if $\\| x^{(t)}-x^{(t-1)}\\|<\\epsilon$ stop. Otherwise go to step 4.\n",
    "\n",
    "$\\rightarrow$ Step 4: $\\rho_{t+1}=\\eta\\rho_{t}$, $t=t+1$, go to step 2.\n",
    "\n",
    "For the gradient method we need the gradient:\n",
    "\n",
    "$$\\nabla f(x)=-\\mu+\\gamma x^T\\Sigma+\\rho(x^Te-1)e$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Definition of the functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def portfolio_barrier(x, mu, covar, gamma, rho):\n",
    "    return -np.dot(x,mu)+0.5*gamma*np.dot(np.dot(x,covar),x.T)+(rho/2)*((np.sum(x)-1)**2)\n",
    "\n",
    "def portfolio_barrier_grad(x, mu, covar, gamma, rho):\n",
    "    return -mu+gamma*np.dot(x,covar)+rho*(np.sum(x)-1)*np.ones(mu.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time elapsed=', 59.933534130792616)\n",
      "('iterations', 46)\n",
      "[ 4.08656029  0.10982576 -4.670807    1.47442095]\n",
      "4.71070065249e-09\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "b=len(mu)\n",
    "x_ini=np.zeros(b) #initial value for x\n",
    "alpha=0.0001\n",
    "n_iter=1000 #maximum number iteration gradient method\n",
    "n_iter_barr=1000 #maximum number iterations barrier algorithm\n",
    "x_iter=np.zeros((b,n_iter_barr))\n",
    "OF_iter=np.zeros(n_iter)\n",
    "tol_iter=np.zeros(n_iter)\n",
    "tol=1000;\n",
    "tol_barr=1000;\n",
    "epsilon=1e-8;#tolerance gradient method\n",
    "epsilon_barr=1e-8;#tolerance barrier method\n",
    "t=1\n",
    "eta=1.5;\n",
    "rho=1;\n",
    "gamma=3;\n",
    "\n",
    "time_start = time.clock()\n",
    "while (t <= n_iter_barr-2) and (tol_barr>epsilon_barr):   \n",
    "    if t==1:\n",
    "        x=x_ini\n",
    "    else:\n",
    "        x=x_iter[:,t-1]\n",
    "    i=0\n",
    "    ################      GRADIENT METHOD    #################################\n",
    "    while (i <= n_iter-2) and (tol>epsilon):\n",
    "        i=i+1\n",
    "        grad=portfolio_barrier_grad(x, mu, covar, gamma, rho)#gradient vector\n",
    "        ddirect=-grad#descent direction\n",
    "        ######Armijo rule to adjust alpha########\n",
    "        sigma = 0.1\n",
    "        beta= 0.5\n",
    "        alpha=1\n",
    "        while (portfolio_barrier(x+alpha*ddirect, mu, covar, gamma, rho) > portfolio_barrier(x, mu, covar, gamma, rho)+alpha*sigma*np.dot(grad,ddirect.T)):\n",
    "            alpha=alpha*beta\n",
    "        #########################################\n",
    "        x=x+alpha*ddirect\n",
    "        tol=np.linalg.norm(grad,ord=2)\n",
    "    ###########################################################################\n",
    "    x_iter[:,t]=x\n",
    "    rho=rho*eta\n",
    "    if t>1:\n",
    "        tol_barr=np.linalg.norm(x_iter[:,t]-x_iter[:,t-1],ord=2)\n",
    "    t=t+1\n",
    "time_elapsed = (time.clock() - time_start) \n",
    "print('time elapsed=',time_elapsed)\n",
    "print('iterations',t)\n",
    "print(x_iter[:,t-1])\n",
    "print(tol_barr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
